import fitz  # PyMuPDF
import pytesseract
from pdf2image import convert_from_bytes
import re
import streamlit as st
from docxtpl import DocxTemplate
import os
import time

# Ch·ªâ ƒë·ªãnh ƒë∆∞·ªùng d·∫´n Tesseract
pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"
POPPLER_PATH = "/usr/bin"  # ƒê∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh tr√™n Linux

st.title("üìú Tr√≠ch xu·∫•t th√¥ng tin th·ª≠a ƒë·∫•t t·ª´ PDF scanner")

def clean_text(text):
    replacements = {
        "m¬∞": "m¬≤",
        "m 2": "m¬≤",
        "l√¥ai": "lo·∫°i",
        "ƒë·ªã·∫°": "ƒë·ªãa",
        "CCCD s√¥": "CCCD s·ªë",
        "GCN:": "Gi·∫•y ch·ª©ng nh·∫≠n:",
        # C√°c l·ªói OCR ph·ªï bi·∫øn v·ªÅ ng√†y th√°ng
        "<t": "1",                  # v√≠ d·ª• <t3 -> 13
        "t3": "13",                 # fallback n·∫øu OCR b·ªè m·∫•t d·∫•u
        "th√°ng .": "th√°ng ",
        "nƒÉm¬≤": "nƒÉm ",
        "nƒÉm:": "nƒÉm ",
        "th√°ng:": "th√°ng ",
        "ng√†y:": "ng√†y ",
        ".": " ",                   # lo·∫°i b·ªè d·∫•u ch·∫•m g√¢y nhi·ªÖu
        "¬≤": "",                    # lo·∫°i b·ªè k√Ω t·ª± m≈© (th∆∞·ªùng OCR nh·∫ßm)
    }

    for wrong, right in replacements.items():
        text = text.replace(wrong, right)

    # D·ªçn kho·∫£ng tr·∫Øng th·ª´a sau khi thay th·∫ø
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def normalize_vietnamese_date(text):
    text = text.lower()
    text = re.sub(r"\s+", " ", text).strip()
    match = re.search(r"ng√†y\s*(\d{1,2})\s*th√°ng\s*(\d{1,2})\s*nƒÉm\s*(\d{4})", text)
    if match:
        day, month, year = match.groups()
        return f"{int(day):02}/{int(month):02}/{year}"
    return ""


# H√†m tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ PDF scan
def extract_text_from_scanned_pdf(pdf_bytes):
    images = convert_from_bytes(pdf_bytes.read(), poppler_path=POPPLER_PATH)
    extracted_text = ""
    for img in images:
        text = pytesseract.image_to_string(img, lang="vie")  # OCR ti·∫øng Vi·ªát
        extracted_text += text + "\n"
    return clean_text(extracted_text)  # √Åp d·ª•ng s·ª≠a l·ªói OCR

def extract_field(text, field_label):
    pattern = rf"[^\n]{{0,10}}{field_label}:\s*([\s\S]*?)(?:\.|\n|$)"
    match = re.search(pattern, text, re.IGNORECASE)
    return match.group(1).strip() if match else ""

def extract_land_info(text):
    text = clean_text(text)  # L√†m s·∫°ch tr∆∞·ªõc khi tr√≠ch xu·∫•t

    # thua_so = re.search(r"Th·ª≠a ƒë·∫•t s·ªë:\s*(\d+)", text, re.IGNORECASE)
    # to_ban_do_so = re.search(r"t·ªù b·∫£n ƒë·ªì s·ªë:\s*(\d+)", text, re.IGNORECASE)
    # dien_tich = re.search(r"Di·ªán t√≠ch:\s*([\d.,]+)\s*m¬≤?", text, re.IGNORECASE)
    thua_so = extract_field(text, "Th·ª≠a ƒë·∫•t s·ªë")
    to_ban_do_so = extract_field(text, "t·ªù b·∫£n ƒë·ªì s·ªë")
    dien_tich = extract_field(text, "Di·ªán t√≠ch")

    # loai_dat = re.search(r"Lo·∫°i ƒë·∫•t:\s*([\s\S]*?)\.", text, re.IGNORECASE)
    loai_dat = extract_field(text, "Lo·∫°i ƒë·∫•t")
    hinh_thuc_su_dung = extract_field(text, "H√¨nh th·ª©c s·ª≠ d·ª•ng ƒë·∫•t")
    dia_chi = extract_field(text, "ƒê·ªãa ch·ªâ")
    thoi_han_su_dung = extract_field(text, "Th·ªùi h·∫°n")
    nguon_goc_su_dung = extract_field(text, "Ngu·ªìn g·ªëc s·ª≠ d·ª•ng")
    thoi_diem_dang_ky = extract_field(text, "Th·ªùi ƒëi·ªÉm ƒëƒÉng k√Ω v√†o s·ªï ƒë·ªãa ch√≠nh")
    so_vao_so_cap_GCN = extract_field(text, "S·ªë v√†o s·ªï c·∫•p Gi·∫•y ch·ª©ng nh·∫≠n")
    # thoi_han_su_dung = re.search(r"Th·ªùi h·∫°n:\s*([\s\S]*?)\.", text, re.IGNORECASE)
    # nguon_goc_su_dung = re.search(r"Ngu·ªìn g·ªëc s·ª≠ d·ª•ng:\s*([\s\S]*?)\.", text, re.IGNORECASE)
    # thoi_diem_dang_ky = re.search(r"Th·ªùi ƒëi·ªÉm ƒëƒÉng k√Ω v√†o s·ªï ƒë·ªãa ch√≠nh:\s*([\s\S]*?)\.", text, re.IGNORECASE)
    # so_vao_so_cap_GCN = re.search(r"S·ªë v√†o s·ªï c·∫•p Gi·∫•y ch·ª©ng nh·∫≠n:\s*([\s\S]*?)\.", text, re.IGNORECASE)
    noi_dung = re.search(r"Ghi ch√∫:\s*([\s\S]*?)\.", text, re.IGNORECASE)

    # T√¨m "ng√†y ... th√°ng ... nƒÉm ..." g·∫ßn cu·ªëi vƒÉn b·∫£n (th∆∞·ªùng l√† ch·ªó k√Ω)
    thoi_diem_dang_ky_GCN_raw = re.search(r"(ng√†y\s*\d{0,2}[\s\S]{0,60}nƒÉm\s*\d{4})", text, re.IGNORECASE)

    # T√¨m v√πng c√≥ "Chi nh√°nh" ƒë·ªÉ b·∫Øt s·ªë ph√°t h√†nh GCN (v√≠ d·ª•: AA 00437154)
    context_match = re.search(r"(CHI NH√ÅNH[\s\S]{0,300})", text, re.IGNORECASE)
    so_phat_hanh_GCN = None
    if context_match:
        context_block = context_match.group(1)
        so_phat_hanh_GCN = re.search(r"\b([A-Z]{2}\s*\d{6,})\b", context_block)

    # Tr√≠ch xu·∫•t ng∆∞·ªùi s·ª≠ d·ª•ng ƒë·∫•t
    nguoi_su_dung_matches = re.findall(
        r"(?:√îng|B√†):\s*([^\n,]+?),\s*CCCD s·ªë:\s*(\d+)(?:,\s*ƒê·ªãa ch·ªâ:\s*([\s\S]*?))?\.",
        text
    )
    nguoi_su_dung = {}
    for i, (ten, cccd, dia_chi_nguoi) in enumerate(nguoi_su_dung_matches, start=1):
        nguoi_su_dung[f"TenNguoi_{i}"] = ten.strip()
        nguoi_su_dung[f"SoCCCD_{i}"] = cccd.strip()
        nguoi_su_dung[f"DiaChiNguoi_{i}"] = dia_chi_nguoi.strip() if dia_chi_nguoi else ""

    return {
        "SoThua": thua_so.group(1).strip() if thua_so else "",
        "SoToBanDo": to_ban_do_so.group(1).strip() if to_ban_do_so else "",
        "DienTich": dien_tich.group(1).strip() if dien_tich else "",
        "LoaiDat": loai_dat.group(1).strip() if loai_dat else "",
        "HinhThucSuDung": hinh_thuc_su_dung.group(1).strip() if hinh_thuc_su_dung else "",
        "DiaChi": dia_chi.group(1).strip() if dia_chi else "",
        "ThoiHanSuDung": thoi_han_su_dung.group(1).strip() if thoi_han_su_dung else "",
        "NguonGocSuDung": nguon_goc_su_dung.group(1).strip() if nguon_goc_su_dung else "",
        "ThoiDiemDangKy": thoi_diem_dang_ky.group(1).strip() if thoi_diem_dang_ky else "",
        "SoPhatHanhGCN": so_phat_hanh_GCN.group(1).strip() if so_phat_hanh_GCN else "",
        "SoVaoSoCapGCN": so_vao_so_cap_GCN.group(1).strip() if so_vao_so_cap_GCN else "",
        "ThoiDiemDangKyGCN": normalize_vietnamese_date(thoi_diem_dang_ky_GCN_raw.group(1)) if thoi_diem_dang_ky_GCN_raw else "",
        "NoiDung": noi_dung.group(1).strip() if noi_dung else ""
    }, nguoi_su_dung


# H√†m ƒëi·ªÅn th√¥ng tin v√†o template DOCX
def fill_template_with_data(template_path, land_info, nguoi_su_dung, new_name=None):
    doc = DocxTemplate(template_path)
    context = {**land_info, **nguoi_su_dung}

    if new_name:
        context["TenNguoi_1"] = new_name.strip()

    doc.render(context)

    # T·∫°o t√™n file ƒë·ªông theo t√™n ng∆∞·ªùi s·ª≠ d·ª•ng
    ten_nguoi = context.get("TenNguoi_1", "nguoi_su_dung").replace(" ", "_")
    output_path = f"GCN_{ten_nguoi}.docx"
    doc.save(output_path)
    return output_path

# Upload file PDF
uploaded_file = st.file_uploader("üìÇ Ch·ªçn file PDF", type=["pdf"])

if uploaded_file:
    text = extract_text_from_scanned_pdf(uploaded_file)
    land_info, nguoi_su_dung = extract_land_info(text)  # Tr√≠ch xu·∫•t th√¥ng tin

    if st.button("üì• Xu·∫•t file DOCX v√† T·∫£i v·ªÅ"):
        with st.spinner("ƒêang xu·∫•t file DOCX..."):
            time.sleep(2)  # Gi·∫£ l·∫≠p th·ªùi gian x·ª≠ l√Ω
            template_path = "template.docx"
            docx_file = fill_template_with_data(template_path, land_info, nguoi_su_dung)

        st.success("Xu·∫•t file th√†nh c√¥ng!")
        
        # Cho ph√©p t·∫£i file DOCX
        with open(docx_file, "rb") as file:
            st.download_button(
                label="T·∫£i file DOCX",
                data=file.read(),
                file_name=docx_file,
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ tr√≠ch xu·∫•t
    st.subheader("üè† Th√¥ng tin th·ª≠a ƒë·∫•t:")
    for key, value in land_info.items():
        st.write(f"**{key}:** {value}")

    # Hi·ªÉn th·ªã th√¥ng tin t·ª´ng ng∆∞·ªùi s·ª≠ d·ª•ng ƒë·∫•t
    st.subheader("üë§ Ng∆∞·ªùi s·ª≠ d·ª•ng ƒë·∫•t:")
    for i in range(1, len(nguoi_su_dung) // 3 + 1):
        st.write(f"**Ng∆∞·ªùi {i}:** {nguoi_su_dung.get(f'TenNguoi_{i}', '')}")
        st.write(f"**CCCD:** {nguoi_su_dung.get(f'SoCCCD_{i}', '')}")
        st.write(f"**ƒê·ªãa ch·ªâ:** {nguoi_su_dung.get(f'DiaChiNguoi_{i}', '')}")

    with st.expander("üìÑ VƒÉn b·∫£n tr√≠ch xu·∫•t t·ª´ PDF (OCR)"):
        st.text_area("N·ªôi dung:", text, height=300)