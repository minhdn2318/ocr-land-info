import pytesseract
from pdf2image import convert_from_bytes
import cv2
import numpy as np
import re
import streamlit as st
from docxtpl import DocxTemplate
import os
import time
import unicodedata
import unidecode

# Ch·ªâ ƒë·ªãnh ƒë∆∞·ªùng d·∫´n Tesseract
pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"
POPPLER_PATH = "/usr/bin"  # ƒê∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh tr√™n Linux

st.title("üìú Tr√≠ch xu·∫•t th√¥ng tin th·ª≠a ƒë·∫•t t·ª´ PDF scanner")

# H√†m ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·ªÉ tƒÉng ch·∫•t l∆∞·ª£ng OCR
def preprocess_image(img):
    img = np.array(img)
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

# Chu·∫©n h√≥a vƒÉn b·∫£n ƒë·∫ßu ra t·ª´ OCR (b·ªè d·∫•u, lowercase, x√≥a k√Ω t·ª± th·ª´a)
def normalize_text(text):
    text = unidecode.unidecode(text)
    text = unicodedata.normalize('NFKC', text)
    text = re.sub(r"\s+", " ", text)  # G·ªôp nhi·ªÅu kho·∫£ng tr·∫Øng
    return text.lower().strip()

# Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ PDF scan
def extract_text_from_scanned_pdf(pdf_bytes):
    images = convert_from_bytes(pdf_bytes.read(), dpi=300, poppler_path=POPPLER_PATH)
    extracted_text = ""
    for img in images:
        processed_img = preprocess_image(img)
        text = pytesseract.image_to_string(processed_img, lang="vie+eng", config="--oem 3 --psm 6")
        extracted_text += text + "\n"
    return extracted_text.strip()

# H√†m tr√≠ch xu·∫•t th√¥ng tin t·ª´ text ƒë√£ normalize
def extract_land_info(text):
    patterns = {
        "SoThua": r"thua dat so\s*(\d+)",
        "SoToBanDo": r"to ban do so\s*(\d+)",
        "DienTich": r"dien tich\s*([\d.,]+)\s*m2?",
        "LoaiDat": r"loai dat\s*([\w\s\-]+)",
        "HinhThucSuDung": r"hinh thuc su dung\s*([\w\s\-]+)",
        "DiaChi": r"dia chi\s*([\w\s\d\-,/.]+)",
        "ThoiHanSuDung": r"thoi han\s*([\w\s\-]+)",
        "NguonGocSuDung": r"nguon goc su dung\s*([\w\s\-]+)",
        "ThoiDiemDangKy": r"thoi diem dang ky vao so dia chinh\s*([\w\s\d\-/.]+)",
        "SoPhatHanhGCN": r"so phat hanh giay chung nhan\s*([\w\d\-/.]+)",
        "SoVaoSoCapGCN": r"so vao so cap giay chung nhan\s*([\w\d\-/.]+)",
        "ThoiDiemDangKyGCN": r"thoi diem dang ky\s*([\w\s\d\-/.]+)",
        "NoiDung": r"ghi chu\s*([\w\s\d\-/.]+)"
    }

    extracted_info = {key: (re.search(pattern, text).group(1).strip() if re.search(pattern, text) else "") for key, pattern in patterns.items()}

    # Tr√≠ch xu·∫•t th√¥ng tin ng∆∞·ªùi s·ª≠ d·ª•ng ƒë·∫•t
    nguoi_su_dung_matches = re.findall(r"(?:ong|ba)\s*[:\-]?\s*([\w\s]+),\s*cccd so[:\-]?\s*(\d+)(?:,\s*dia chi[:\-]?\s*([\w\s\d\-,/.]+))?", text)
    nguoi_su_dung = {f"TenNguoi_{i+1}": ten.strip() for i, (ten, _, _) in enumerate(nguoi_su_dung_matches)}
    nguoi_su_dung.update({f"SoCCCD_{i+1}": cccd.strip() for i, (_, cccd, _) in enumerate(nguoi_su_dung_matches)})
    nguoi_su_dung.update({f"DiaChiNguoi_{i+1}": dia_chi.strip() if dia_chi else "" for i, (_, _, dia_chi) in enumerate(nguoi_su_dung_matches)})

    return extracted_info, nguoi_su_dung

# ƒêi·ªÅn v√†o template DOCX
def fill_template_with_data(template_path, land_info, nguoi_su_dung):
    doc = DocxTemplate(template_path)
    context = {**land_info, **nguoi_su_dung}
    output_path = "output_land_info.docx"
    doc.render(context)
    doc.save(output_path)
    return output_path

# Giao di·ªán Streamlit
uploaded_file = st.file_uploader("üìÇ Ch·ªçn file PDF", type=["pdf"])

if uploaded_file:
    text = extract_text_from_scanned_pdf(uploaded_file)
    normalized_text = normalize_text(text)
    land_info, nguoi_su_dung = extract_land_info(normalized_text)

    if st.button("üì• Xu·∫•t file DOCX v√† T·∫£i v·ªÅ"):
        with st.spinner("ƒêang xu·∫•t file DOCX..."):
            time.sleep(2)
            template_path = "template.docx"
            docx_file = fill_template_with_data(template_path, land_info, nguoi_su_dung)

        st.success("Xu·∫•t file th√†nh c√¥ng!")
        with open(docx_file, "rb") as file:
            st.download_button(
                label="üì• T·∫£i file DOCX",
                data=file.read(),
                file_name=docx_file,
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )

    st.subheader("üè† Th√¥ng tin th·ª≠a ƒë·∫•t:")
    for key, value in land_info.items():
        st.write(f"**{key}:** {value}")

    st.subheader("üë§ Ng∆∞·ªùi s·ª≠ d·ª•ng ƒë·∫•t:")
    for i in range(1, len(nguoi_su_dung) // 3 + 1):
        st.write(f"**Ng∆∞·ªùi {i}:** {nguoi_su_dung.get(f'TenNguoi_{i}', '')}")
        st.write(f"**CCCD:** {nguoi_su_dung.get(f'SoCCCD_{i}', '')}")
        st.write(f"**ƒê·ªãa ch·ªâ:** {nguoi_su_dung.get(f'DiaChiNguoi_{i}', '')}")
